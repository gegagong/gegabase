<!DOCTYPE html>
<html lang="en">
<!--
This HTML document creates a web application for real-time musical note detection and visualization.

Purpose:
The application captures audio input from the user's microphone, detects the pitch in real-time, 
converts the detected pitch to a musical note, and displays these notes on an interactive graph. 
It allows users to customize various aspects of the detection and visualization process, 
applies audio filtering techniques to improve accuracy, and highlights notes based on musical scales.

Key Components and Functionality:

1. Audio Capture and Analysis:
   - Initializes audio context and manages the audio analysis process
   - Implements real-time pitch detection using autocorrelation algorithm
   - Converts detected frequencies to MIDI note numbers and musical note names

2. Visualization:
   - Utilizes Chart.js to create a dynamic graph of detected notes over time
   - Displays note labels on both left and right y-axes for easy reading
   - Color-codes notes based on their inclusion in the selected musical scale (red for in-scale, black for out-of-scale)
   - Allows customization of the displayed note range

3. User Interface and Customization:
   - Provides a responsive interface adaptable to various screen sizes, including mobile devices
   - Allows users to adjust the range of displayed notes
   - Enables selection of a root note and scale type (major/minor) for note highlighting
   - Offers real-time adjustment of audio filtering parameters

4. Audio Filtering and Processing:
   - Implements a noise gate to reduce sensitivity to background noise
   - Applies a low-pass filter to attenuate high-frequency noise
   - Uses a smoothing algorithm to stabilize note detection and reduce fluctuations

5. Musical Scale Integration:
   - Generates major and minor scales based on a user-selected root note
   - Dynamically updates the chart to highlight notes belonging to the selected scale
   - Enhances musical relevance of the visualization for educational and practice purposes

6. Responsive Design:
   - Adapts the interface and functionality for both desktop and mobile devices
   - Implements a full-screen graph on desktop and a toggle-able customization menu on mobile
   - Handles window resize events to maintain optimal display
   
7. Mobile Responsiveness:
   - Implements a toggle-able customization menu specifically for mobile devices
   - Adjusts chart height and layout for optimal viewing on smaller screens

8. Real-time Settings Adjustment:
   - Allows users to modify parameters such as note range, audio filtering, and scale selection on-the-fly
   - Immediately updates the visualization to reflect changed settings without restarting the audio analysis

9. Enhanced Visualization:
   - Utilizes dual y-axis labeling (left and right) for improved note readability
   - Implements dynamic color-coding of both plotted points and y-axis labels based on the selected musical scale

10. Advanced Audio Processing:
    - Employs a weighted average smoothing algorithm to reduce note fluctuations and improve stability
    - Provides fine-grained control over noise gate, low-pass filter, and smoothing factor

11. Extensive Chart.js Customization:
    - Tailors the Chart.js library to create a specialized musical note visualization
    - Implements custom callbacks for dynamic color changes and note labeling

These additional features enhance the application's usability, responsiveness, and overall effectiveness 
as a tool for real-time musical note detection and visualization across various devices and use cases.

Technical Implementation:
- Utilizes Web Audio API for audio processing and analysis
- Employs Chart.js for data visualization
- Implements custom algorithms for pitch detection, note mapping, and scale generation
- Uses responsive design techniques for cross-device compatibility

This application serves as a tool for musicians, music students, and anyone interested in pitch 
recognition and musical scale study. It provides real-time feedback on sung or played notes, 
helping users improve their pitch accuracy and understand the relationship between notes in 
different musical scales.

The combination of audio analysis, dynamic visualization, and musical theory integration 
makes this a versatile application for music education, practice, and exploration of pitch 
and scale relationships in a visual and interactive manner.
-->
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Note Detection App</title>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        #chartContainer {
            width: 100%;
            height: 100vh;
            max-width: none;
            margin: 0;
        }
        .mobile #chartContainer {
            height: calc(100vh - 60px); /* Adjust for mobile header */
        }
        button {
            font-size: 16px;
            margin: 10px;
            padding: 5px 10px;
        }
        .button-container {
            display: flex;
            justify-content: space-between;
        }
        #customizationGUI {
            margin: 20px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
            display: none;
        }
        .mobile #customizationGUI {
            position: fixed;
            top: 60px;
            left: 0;
            right: 0;
            background: white;
            z-index: 1000;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
        }
        #customizationGUI label {
            display: inline-block;
            width: 100px;
        }
        .note-translation {
            margin-left: 10px;
            font-style: italic;
        }
        #mobileCustomizeButton {
            display: none;
        }
        .mobile #mobileCustomizeButton {
            display: inline-block;
        }
        .mobile #toggleCustomizationButton {
            display: none;
        }
    </style>
</head>
<body>
    <div>
        <button id="startButton">Start</button>
        <button id="endButton" disabled>End</button>
        <button id="toggleCustomizationButton">Menu</button>
        <button id="mobileCustomizeButton">Menu</button>
    </div>
    <div id="customizationGUI">
        <h3 style="text-align: center;">Menu</h3>
        <div>
            <label for="minNote">Min Note:</label>
            <input type="number" id="minNote" min="0" max="127" value="48">
            <span id="minNoteTranslation" class="note-translation"></span>
        </div>
        <div>
            <label for="maxNote">Max Note:</label>
            <input type="number" id="maxNote" min="0" max="127" value="84">
            <span id="maxNoteTranslation" class="note-translation"></span>
        </div>
        <div>
            <label for="noiseGate">Noise Gate (dB):</label>
            <input type="number" id="noiseGate" min="-100" max="0" value="-50">
        </div>
        <div>
            <label for="lowPassCutoff">Low-Pass Cutoff (Hz):</label>
            <input type="number" id="lowPassCutoff" min="0" max="20000" value="5000">
        </div>
        <div>
            <label for="smoothingFactor">Smoothing Factor:</label>
            <input type="number" id="smoothingFactor" min="0" max="1" step="0.1" value="0.8">
        </div>
        <div>
            <label for="scaleRoot">Scale Root:</label>
            <select id="scaleRoot">
                <option value="0">C</option>
                <option value="1">C#/Db</option>
                <option value="2">D</option>
                <option value="3">D#/Eb</option>
                <option value="4">E</option>
                <option value="5">F</option>
                <option value="6">F#/Gb</option>
                <option value="7">G</option>
                <option value="8">G#/Ab</option>
                <option value="9">A</option>
                <option value="10">A#/Bb</option>
                <option value="11">B</option>
            </select>
        </div>
        <div>
            <label for="scaleType">Scale Type:</label>
            <select id="scaleType">
                <option value="major">Major</option>
                <option value="minor">Minor</option>
                <!-- ... add other scale types if desired ... -->
            </select>
        </div>
        <div class="button-container">
            <button id="clearGraphButton">Clear Graph</button>
            <button id="saveSettingsButton">Save Settings</button>
        </div>
    </div>
    <div id="chartContainer">
        <canvas id="noteChart"></canvas>
    </div>

    <script>
        let audioContext;
        let analyser;
        const noteData = [];
        let isRunning = false;
        let isMobile;
        let chart;
        let noiseGate;
        let lowPassFilter;
        let smoothingFactor;
        let mediaStream = null;
    
        let currentSettings = {
            minNote: 48,
            maxNote: 84,
            noiseGate: -50,
            lowPassCutoff: 5000,
            smoothingFactor: 0.8,
            scaleRoot: 0,
            scaleType: 'major'
        };
    
        const startButton = document.getElementById('startButton');
        const endButton = document.getElementById('endButton');
        const toggleCustomizationButton = document.getElementById('toggleCustomizationButton');
        const mobileCustomizeButton = document.getElementById('mobileCustomizeButton');
        const customizationGUI = document.getElementById('customizationGUI');
        const clearGraphButton = document.getElementById('clearGraphButton');
        const minNoteInput = document.getElementById('minNote');
        const maxNoteInput = document.getElementById('maxNote');
        const minNoteTranslation = document.getElementById('minNoteTranslation');
        const maxNoteTranslation = document.getElementById('maxNoteTranslation');
        const noiseGateInput = document.getElementById('noiseGate');
        const lowPassCutoffInput = document.getElementById('lowPassCutoff');
        const smoothingFactorInput = document.getElementById('smoothingFactor');
        const saveSettingsButton = document.getElementById('saveSettingsButton');
        const scaleRootInput = document.getElementById('scaleRoot');
        const scaleTypeInput = document.getElementById('scaleType');
    
        startButton.addEventListener('click', startAudioAnalysis);
        endButton.addEventListener('click', endAudioAnalysis);
        clearGraphButton.addEventListener('click', clearGraph);
        toggleCustomizationButton.addEventListener('click', toggleCustomizationGUI);
        mobileCustomizeButton.addEventListener('click', toggleCustomizationGUI);
        minNoteInput.addEventListener('input', updateNoteTranslation);
        maxNoteInput.addEventListener('input', updateNoteTranslation);
        saveSettingsButton.addEventListener('click', saveSettings);
    
        const ctx = document.getElementById('noteChart').getContext('2d');
    
        function isMobileDevice() {
            return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
        }
        
        function initializeApp() {
            isMobile = isMobileDevice();
            if (isMobile) {
                document.body.classList.add('mobile');
            }
    
            chart = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: [],
                    datasets: [{
                        label: 'Detected Note',
                        data: [],
                        borderColor: function(context) {
                            const index = context.dataIndex;
                            const value = context.dataset.data[index];
                            const noteNumber = Math.round(value) % 12;
                            const scale = getScale(currentSettings.scaleRoot, currentSettings.scaleType);
                            return scale.includes(noteNumber) ? 'red' : 'black';
                        },
                        pointBackgroundColor: function(context) {
                            const index = context.dataIndex;
                            const value = context.dataset.data[index];
                            const noteNumber = Math.round(value) % 12;
                            const scale = getScale(currentSettings.scaleRoot, currentSettings.scaleType);
                            return scale.includes(noteNumber) ? 'red' : 'black';
                        },
                        tension: 0.1,
                        pointRadius: 3
                    }]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: !isMobile,
                    scales: {
                        y: {
                            beginAtZero: false,
                            min: currentSettings.minNote,
                            max: currentSettings.maxNote,
                            ticks: {
                                stepSize: 1,
                                callback: function(value) {
                                    return translateNoteNumber(value);
                                },
                                color: 'black'
                            }
                        },
                        y2: {
                            position: 'right',
                            beginAtZero: false,
                            min: currentSettings.minNote,
                            max: currentSettings.maxNote,
                            ticks: {
                                stepSize: 1,
                                callback: function(value) {
                                    return translateNoteNumber(value);
                                },
                                color: 'black'
                            }
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'Time (seconds)'
                            }
                        }
                    },
                    animation: {
                        duration: 0
                    },
                    plugins: {
                        title: {
                            display: true,
                            text: 'Detected Musical Notes Over Time'
                        },
                        legend: {
                            display: false
                        }
                    }
                }
            });
            
            scaleRootInput.value = currentSettings.scaleRoot;
            updateNoteTranslation();
    
            if (!isMobile) {
                handleResize();
            }
        }
        
        function clearGraph() {
            noteData.length = 0;  // Clear the data array
            chart.data.labels = [];  // Clear labels
            chart.data.datasets[0].data = [];  // Clear dataset
            chart.update();  // Update the chart
        }

        function saveSettings() {
            currentSettings.minNote = parseInt(minNoteInput.value);
            currentSettings.maxNote = parseInt(maxNoteInput.value);
            currentSettings.noiseGate = parseFloat(noiseGateInput.value);
            currentSettings.lowPassCutoff = parseFloat(lowPassCutoffInput.value);
            currentSettings.smoothingFactor = parseFloat(smoothingFactorInput.value);
            currentSettings.scaleRoot = parseInt(scaleRootInput.value);
            currentSettings.scaleType = scaleTypeInput.value;
    
            updateChartRange();
            updateNoiseGate();
            updateLowPassCutoff();
            updateSmoothingFactor();
            updateScaleRoot();
            updateChartLabels();
            updateChartColors();
        }
    
        function updateChartRange() {
            chart.options.scales.y.min = currentSettings.minNote;
            chart.options.scales.y.max = currentSettings.maxNote;
            chart.options.scales.y2.min = currentSettings.minNote;
            chart.options.scales.y2.max = currentSettings.maxNote;

            chart.options.scales.y.ticks.stepSize = 1;
            chart.options.scales.y.ticks.autoSkip = false;
            chart.options.scales.y2.ticks.stepSize = 1;
            chart.options.scales.y2.ticks.autoSkip = false;
            chart.update();
        }
    
        function updateNoteTranslation() {
            minNoteTranslation.textContent = translateNoteNumber(minNoteInput.value);
            maxNoteTranslation.textContent = translateNoteNumber(maxNoteInput.value);
        }
    
        function updateNoiseGate() {
            noiseGate = currentSettings.noiseGate;
        }
    
        function updateLowPassCutoff() {
            if (audioContext && lowPassFilter) {
                lowPassFilter.frequency.setValueAtTime(currentSettings.lowPassCutoff, audioContext.currentTime);
            }
        }
    
        function updateSmoothingFactor() {
            smoothingFactor = currentSettings.smoothingFactor;
        }
    
        function updateChartLabels() {
            chart.options.scales.y.ticks = {
                stepSize: 1,
                callback: function(value) {
                    return translateNoteNumber(value);
                }
            };
            chart.options.scales.y2.ticks = {
                stepSize: 1,
                callback: function(value) {
                    return translateNoteNumber(value);
                }
            };
            chart.update();
        }
    
        function updateChartColors() {
            const scale = getScale(currentSettings.scaleRoot, currentSettings.scaleType);
            
            function isInScale(note) {
                const noteNumber = Math.round(note) % 12;
                return scale.includes(noteNumber);
            }

            chart.data.datasets[0].pointBackgroundColor = function(context) {
                const value = context.dataset.data[context.dataIndex];
                return isInScale(value) ? 'red' : 'black';
            };
            
            chart.data.datasets[0].borderColor = function(context) {
                const value = context.dataset.data[context.dataIndex];
                return isInScale(value) ? 'red' : 'black';
            };

            // Update y-axis and y2-axis label colors
            chart.options.scales.y.ticks.color = function(context) {
                return isInScale(context.tick.value) ? 'red' : 'black';
            };

            chart.options.scales.y2.ticks.color = function(context) {
                return isInScale(context.tick.value) ? 'red' : 'black';
            };
            
            chart.update();
        }
    
        function getScale(root, type) {
            const majorScale = [0, 2, 4, 5, 7, 9, 11];
            const minorScale = [0, 2, 3, 5, 7, 8, 10];
            const scale = type === 'major' ? majorScale : minorScale;
            return scale.map(interval => (interval + root) % 12);
        }
    
        function translateNoteNumber(noteNumber) {
            const notes = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'];
            const octave = Math.floor(noteNumber / 12) - 1;
            const noteName = notes[noteNumber % 12];
            return `${noteName}${octave}`;
        }
    
        function toggleCustomizationGUI() {
            if (customizationGUI.style.display === 'none' || customizationGUI.style.display === '') {
                customizationGUI.style.display = 'block';
            } else {
                customizationGUI.style.display = 'none';
            }
        }
    
        function startAudioAnalysis() {
            if (!isRunning) {
                isRunning = true;
                startButton.disabled = true;
                endButton.disabled = false;
                noteData.length = 0;  // Clear previous data
    
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                lowPassFilter = audioContext.createBiquadFilter();
                lowPassFilter.type = "lowpass";
                lowPassFilter.frequency.setValueAtTime(currentSettings.lowPassCutoff, audioContext.currentTime);
                
                navigator.mediaDevices.getUserMedia({ audio: true, video: false })
                    .then(stream => {
                        const source = audioContext.createMediaStreamSource(stream);
                        analyser = audioContext.createAnalyser();
                        analyser.fftSize = 2048;
                        source.connect(lowPassFilter);
                        lowPassFilter.connect(analyser);
                        
                        detectPitch();
                    })
                    .catch(err => console.error('Error accessing microphone:', err));
            }
        }
    
        function endAudioAnalysis() {
            isRunning = false;
            startButton.disabled = false;
            endButton.disabled = true;
            if (audioContext && audioContext.state === 'running') {
                audioContext.close().then(() => {
                    audioContext = null;
                    analyser = null;
                });
            }
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
        }
    
        let lastNote = -1;
    
        function detectPitch() {
            if (!isRunning) return;
    
            const bufferLength = analyser.fftSize;
            const buffer = new Float32Array(bufferLength);
            analyser.getFloatTimeDomainData(buffer);
    
            // Apply noise gate
            const rms = getRMS(buffer);
            if (20 * Math.log10(rms) < currentSettings.noiseGate) {
                requestAnimationFrame(detectPitch);
                return;
            }
    
            const frequency = autoCorrelate(buffer, audioContext.sampleRate);
            if (frequency > 0) {
                let note = frequencyToNote(frequency);
                
                // Apply smoothing
                if (lastNote !== -1) {
                    note = lastNote * currentSettings.smoothingFactor + note * (1 - currentSettings.smoothingFactor);
                }
                lastNote = note;
    
                console.log(`Detected frequency: ${frequency.toFixed(2)} Hz, Note: ${translateNoteNumber(Math.round(note))}`);
                noteData.push(note);
                updateChart();
            }
    
            requestAnimationFrame(detectPitch);
        }
    
        function getRMS(buffer) {
            let sum = 0;
            for (let i = 0; i < buffer.length; i++) {
                sum += buffer[i] * buffer[i];
            }
            return Math.sqrt(sum / buffer.length);
        }
    
        function autoCorrelate(buffer, sampleRate) {
            let SIZE = buffer.length;
            let sumOfSquares = 0;
            for (let i = 0; i < SIZE; i++) {
                let val = buffer[i];
                sumOfSquares += val * val;
            }
            let rootMeanSquare = Math.sqrt(sumOfSquares / SIZE);
            if (rootMeanSquare < 0.01) {
                return -1; // not enough signal
            }
    
            let r1 = 0, r2 = SIZE - 1, thres = 0.2;
            for (let i = 0; i < SIZE / 2; i++) {
                if (Math.abs(buffer[i]) < thres) { r1 = i; break; }
            }
            for (let i = 1; i < SIZE / 2; i++) {
                if (Math.abs(buffer[SIZE - i]) < thres) { r2 = SIZE - i; break; }
            }
    
            buffer = buffer.slice(r1, r2);
            SIZE = buffer.length;
    
            let c = new Array(SIZE).fill(0);
            for (let i = 0; i < SIZE; i++) {
                for (let j = 0; j < SIZE - i; j++) {
                    c[i] = c[i] + buffer[j] * buffer[j + i];
                }
            }
    
            let d = 0;
            while (c[d] > c[d + 1]) d++;
            let maxval = -1, maxpos = -1;
            for (let i = d; i < SIZE; i++) {
                if (c[i] > maxval) {
                    maxval = c[i];
                    maxpos = i;
                }
            }
            let T0 = maxpos;
    
            let x1 = c[T0 - 1], x2 = c[T0], x3 = c[T0 + 1];
            let a = (x1 + x3 - 2 * x2) / 2;
            let b = (x3 - x1) / 2;
            if (a) T0 = T0 - b / (2 * a);
    
            return sampleRate / T0;
        }
    
        function frequencyToNote(frequency) {
            return 69 + 12 * Math.log2(frequency / 440);
        }
    
        function updateChart() {
            const labels = noteData.map((_, index) => (index * 0.1).toFixed(1));
            chart.data.labels = labels;
            chart.data.datasets[0].data = noteData;
            
            if (!isMobile) {
                chart.options.maintainAspectRatio = false;
                chart.canvas.style.height = '100vh';
            }
    
            chart.update();
        }

        function updateScaleRoot() {
            currentSettings.scaleRoot = parseInt(scaleRootInput.value);
            updateChartColors();
        }
    
        function handleResize() {
            if (!isMobile) {
                chart.options.maintainAspectRatio = false;
                chart.canvas.style.height = '100vh';
                chart.resize();
            }
        }
    
        window.addEventListener('resize', handleResize);
    
        // Initialize the app immediately
        initializeApp();
    </script>
</body>
</html>